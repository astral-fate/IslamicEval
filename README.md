
## üìú Abstract

This paper introduces a system for the IslamicEval 2025 Shared Task 1A, which focuses on identifying Quranic verses (Ayahs) and Prophetic sayings (Hadiths) within text generated by Large Language Models (LLMs). The approach uses a fine-tuned **AraBERTv2** model to treat the task as a token classification problem.

The project's key contribution is a novel **rule-based data generation pipeline**. This pipeline automatically creates a large, high-quality training dataset from authentic religious texts, which removes the need for expensive and time-consuming manual annotation. The system works by embedding these religious texts into templates that simulate how LLMs typically cite sources. This method proved highly effective, achieving an **F1-score of 66.97%** on the official test set.

---

## ü§ñ System Overview

The system is built as a token classification model designed to label each token in a given text as part of an Ayah, a Hadith, or as unrelated ("Outside") text.

### Core Model

The system's foundation is **AraBERTv2**, a powerful transformer-based model pre-trained on a large Arabic text corpus. It was fine-tuned to classify tokens into one of five labels based on the standard BIO schema: **B-Ayah** (Beginning of Ayah), **I-Ayah** (Inside Ayah), **B-Hadith** (Beginning of Hadith), **I-Hadith** (Inside Hadith), and **O** (Outside).

### Rule-Based Training Data Generation

The most innovative part of this work is the pipeline for programmatically generating training data. This approach was chosen to create clean, high-quality data that mimics the structure of LLM responses while avoiding the unpredictable nature of generative models.



The process works in five steps:
1.  **Data Sourcing**: Authentic Quranic and Hadith texts were extracted from `quran.json` and `six_hadith__books.json` files.
2.  **Template Creation**: A list of common Arabic prefixes (e.g., "ŸÇÿßŸÑ ÿßŸÑŸÑŸá ÿ™ÿπÿßŸÑŸâ:") and suffixes (e.g., "ÿµÿØŸÇ ÿßŸÑŸÑŸá ÿßŸÑÿπÿ∏ŸäŸÖ.") was compiled.
3.  **Contextual Embedding**: Each religious text was programmatically wrapped with a randomly chosen prefix and suffix to create a realistic training example.
4.  **Noise Injection**: To better simulate real-world LLM outputs, neutral Arabic sentences were sometimes inserted into the examples.
5.  **Automatic Labeling**: Since the exact start and end positions of the religious texts were known, the BIO labels were generated automatically for every token.

This pipeline allowed for the rapid creation of tens of thousands of perfectly labeled training examples without any manual work.

---

## üõ†Ô∏è Experimental Setup

### Evaluation Metric

The official metric for the task was the character-level **span-based F1-score**. This score is the harmonic mean of Precision and Recall, providing a single, balanced measure of a system's accuracy.

### Implementation Details

* **Model**: `aubmindlab/bert-base-arabertv2`.
* **Training Strategy**: The model was trained for up to 10 epochs, using an early stopping callback with a patience of 3 to prevent overfitting.
* **Learning Rate**: 2e-5.
* **Effective Batch Size**: 16 (4 per device with a gradient accumulation of 4).
* **Hardware**: NVIDIA GeForce RTX 2060 GPU.
* **Libraries**: Hugging Face `transformers`, `datasets`, and `torch`.

---

## üìà Results and Analysis

Experiments were run to compare different methodologies, with the results clearly showing that the rule-based data generation approach was superior.

### Summary of Experimental Results

The F1 scores on the official test set confirm the effectiveness of the proposed model.

| Methodology                | Key Features                                                     | F1 Score |
| :------------------------- | :--------------------------------------------------------------- | :------- |
| **Rule-Based Model** | Rule-based templates with prefixes, suffixes, and neutral sentences. | **66.97%** |
| **Ablation: Generative Data** | Used AraGPT2 to generate context around religious texts.         | 50.50%   |
| **Ablation: Basic Fine-Tuning** | Fine-tuned on raw religious texts without contextual templates.   | 44.70%   |
| **Ablation: Database Lookup** | Simple, normalized exact string matching from source texts.      | 34.80%   |

### Discussion

* **Rule-Based System Success**: The rule-based pipeline achieved the highest F1 score (66.97%) by creating a large, high-quality, and perfectly-labeled dataset that effectively trained the model for the task.
* **Generative Data Ineffectiveness**: Using AraGPT2 to generate context was less effective (50.50% F1), as the generated text was often too generic and didn't accurately mirror how a sophisticated LLM would embed a citation.
* **Context is Crucial**: The poor performance of basic fine-tuning without context (44.70% F1) shows that simply training on raw religious texts isn't enough; the model must learn from examples that simulate a real LLM response.
* **Database Lookup Fails**: Simple string matching performed the worst (34.80% F1) because it's too rigid and can't handle minor variations like punctuation changes or paraphrasing commonly found in LLM outputs.

---

## ‚úÖ Conclusion

The paper presented a successful system for identifying religious texts in LLM outputs using an AraBERTv2 model. Its main contribution is a programmatic, rule-based pipeline for generating training data, a method that proved far more effective than generative augmentation or simple lookup methods. The primary limitation is the system's reliance on the quality of hand-crafted templates.

# resources

- https://github.com/islamAndAi/QURAN-NLP
- https://huggingface.co/Ellbendls/Qwen3-4b-Quran-LoRA-Fine-Tuned
